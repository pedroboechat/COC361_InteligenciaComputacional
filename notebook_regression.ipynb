{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rede Neural - Regressão** <br> COC361 - Inteligência Computacional (2021.2)\n",
    "### Alunos: <br> Henrique Chaves (DRE 119025571) <br> Pedro Boechat (DRE 119065050)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas padrão\n",
    "from os import (\n",
    "    listdir,\n",
    "    makedirs\n",
    ")\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "# Bibliotecas do Jupyter\n",
    "from IPython.display import display\n",
    "\n",
    "# Bibliotecas para manipulação dos dados\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Tensorflow/Keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.config import list_physical_devices\n",
    "from keras.engine.sequential import Sequential as TypeSequential\n",
    "\n",
    "# Bibliotecas para plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Carregamento das variáveis de ambiente\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Número de GPUs disponíveis para o Tensorflow/Keras\n",
    "print(\"Número de GPUs disponíveis: \", len(list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Download do dataset ([Link](https://www.kaggle.com/contactprad/bike-share-daily-data?select=bike_sharing_daily.csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria pasta de destino, caso não exista\n",
    "makedirs(\"./data/regression\", exist_ok=True)\n",
    "\n",
    "# Se a pasta de destino estiver vazia, baixa os dados\n",
    "if len(listdir(\"./data/regression/\")) == 0:\n",
    "    kaggle.api.dataset_download_file(\n",
    "        \"contactprad/bike-share-daily-data\",\n",
    "        \"bike_sharing_daily.csv\",\n",
    "        \"./data/regression/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "df = pd.read_csv(\"./data/regression/bike_sharing_daily.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### • Estudo do dataset\n",
    "```\n",
    "- dteday : date\n",
    "- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "- yr : year (0: 2011, 1:2012)\n",
    "- mnth : month ( 1 to 12)\n",
    "- hr : hour (0 to 23)\n",
    "- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "- weekday : day of the week\n",
    "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "- weathersit : \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "- casual: count of casual users\n",
    "- registered: count of registered users\n",
    "- cnt: count of total rental bikes including both casual and registered\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remover coluna `instant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove coluna `instant` se for igual ao índice do dataset\n",
    "if np.all(df.index == df[\"instant\"] - 1):\n",
    "    df = df.drop(\"instant\", axis=1)\n",
    "\n",
    "print(\"df shape:\", df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Converter coluna `season` para variáveis dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_season = pd.get_dummies(df[\"season\"], drop_first=True)\n",
    "dummies_season = dummies_season.rename(\n",
    "    columns={\n",
    "        2: \"is_summer\",\n",
    "        3: \"is_fall\",\n",
    "        4: \"is_winter\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"dummies_season shape:\", dummies_season.shape)\n",
    "dummies_season.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"season\", axis=1)\n",
    "df = pd.concat([df, dummies_season], axis=1)\n",
    "print(\"df shape:\", df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Converter colunas `mnth` e `weekday` para variáveis cíclicas usando `sin` e `cos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mnth_cos\"] = np.cos(df[\"mnth\"]*np.pi/6)\n",
    "df[\"mnth_sin\"] = np.cos(df[\"mnth\"]*np.pi/6)\n",
    "df[\"weekday_cos\"] = np.cos((df[\"weekday\"]+1)*2*np.pi/7)\n",
    "df[\"weekday_sin\"] = np.cos((df[\"weekday\"]+1)*2*np.pi/7)\n",
    "\n",
    "df = df.drop([\"mnth\", \"weekday\"], axis=1)\n",
    "print(\"df shape:\", df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Desnormalizar colunas `temp`, `atemp`, `hum` e `windspeed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp\"] *= 41\n",
    "df[\"atemp\"] *= 50\n",
    "df[\"hum\"] *= 100\n",
    "df[\"windspeed\"] *= 67\n",
    "\n",
    "print(\"df shape:\", df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Remover colunas `casual` e `registered` pois a soma delas é igual a `cnt` (variável alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(df[\"casual\"] + df[\"registered\"] == df[\"cnt\"]):\n",
    "    df = df.drop([\"casual\", \"registered\"], axis=1)\n",
    "\n",
    "print(\"df shape:\", df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Salvar dataset limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/regression/df_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Definindo `features` e  `targets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"yr\", \"holiday\", \"workingday\", \"weathersit\",\n",
    "            \"temp\", \"atemp\", \"hum\", \"windspeed\",\n",
    "            \"is_summer\", \"is_fall\", \"is_winter\",\n",
    "            \"mnth_cos\", \"mnth_sin\", \"weekday_cos\", \"weekday_sin\"]\n",
    "\n",
    "targets = [\"cnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[features]\n",
    "\n",
    "print(\"df_X shape:\", df_X.shape)\n",
    "df_X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df[targets]\n",
    "\n",
    "print(\"df_y shape:\", df_y.shape)\n",
    "df_y.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do scaler\n",
    "scaler = MinMaxScaler\n",
    "\n",
    "# Instância do scaler para X e Y\n",
    "X_scaler = scaler()\n",
    "y_scaler = scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaler.fit_transform(df_X)\n",
    "y = y_scaler.fit_transform(df_y)\n",
    "\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Definição de callbacks da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    n_hidden_layers: int,\n",
    "    n_neurons: int,\n",
    "    dropout_rate: float,\n",
    "    dropout_last_layer: bool,\n",
    "    learning_rate: float = 0.001,\n",
    "    input_shape: Tuple[int, ] = (X.shape[1], )\n",
    ") -> TypeSequential:\n",
    "    \"\"\"Função que retorna o modelo compilado a partir dos parâmetros.\n",
    "    Args:\n",
    "        n_layers (int): Número de camadas da rede. 2 por padrão.\n",
    "        n_neurons (int): Número de neurônios da rede. 32 por padrão.\n",
    "        dropout_rate (float): Taxa de dropout. 0.2 por padrão.\n",
    "        dropout_last_layer (bool): Se terá dropout na última camada.\n",
    "        False por padrão.\n",
    "        learning_rate (float): Learning rate do modelo. 0.001 por padrão.\n",
    "        input_shape (List[int]): Forma da entrada. [99] por padrão.\n",
    "    \"\"\"\n",
    "    # Criação do modelo sequencial\n",
    "    model = Sequential()\n",
    "\n",
    "    # Número de variáveis de entrada\n",
    "    model.add(\n",
    "            Dense(\n",
    "                n_neurons,\n",
    "                activation='relu',\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i in range(n_hidden_layers):\n",
    "        # Camada de adensamento com ativação RELU\n",
    "        model.add(\n",
    "            Dense(\n",
    "                n_neurons,\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Camada de dropout\n",
    "        if dropout_rate > 0.0:\n",
    "            if (i == n_hidden_layers - 1) and (not dropout_last_layer):\n",
    "                continue\n",
    "            model.add(\n",
    "                Dropout(\n",
    "                    dropout_rate\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Camada de adensamento com ativação LINEAR\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Otimizador Adam\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Compilação do modelo\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduz a learning rate caso o modelo esteja estagnado\n",
    "lr_reduce = ReduceLROnPlateau(\n",
    "    min_delta=1e-5,\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Lista contendo os checkpoints definidos\n",
    "callbacks = [\n",
    "    lr_reduce\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Definição das camadas da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do regressor com wrapper do SKLearn\n",
    "regressor = KerasRegressor(\n",
    "    model=create_model,\n",
    "    n_hidden_layers=1,\n",
    "    n_neurons=32,\n",
    "    dropout_rate=0.0,\n",
    "    dropout_last_layer=False,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros para o Grid Search\n",
    "param_grid = {\n",
    "    \"n_hidden_layers\": [1, 2, 3],\n",
    "    \"n_neurons\": [32, 64, 128],\n",
    "    \"dropout_rate\": [0.0, 0.1, 0.2],\n",
    "    \"dropout_last_layer\": [False, True],\n",
    "    \"learning_rate\": np.logspace(-4, -2, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instância do Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=regressor,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=10,\n",
    "    n_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### • Treino da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Treino do modelo\n",
    "grid_result = grid_search.fit(\n",
    "    X, y,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/regression/grid_result.pkl\", \"wb\") as f:\n",
    "    pickle.dump(grid_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = grid_result.best_estimator_.model.model.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### • Avaliação da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos subplots\n",
    "fig, ax = plt.subplots(figsize=(15, 16), nrows=2)\n",
    "\n",
    "# Gráfico do MAE do modelo por época\n",
    "ax[0].plot(history['mse'])\n",
    "ax[0].plot(history['val_mae'])\n",
    "ax[0].set_title('MAE do modelo por época', fontsize=18)\n",
    "ax[0].set_ylabel('MAE', fontsize=14)\n",
    "ax[0].set_xlabel('Época', fontsize=14)\n",
    "ax[0].legend(['Treino', 'Validação'], loc='upper left', fontsize=16)\n",
    "\n",
    "# Gráfico da loss do modelo por época\n",
    "ax[1].plot(history['loss'])\n",
    "ax[1].plot(history['val_loss'])\n",
    "ax[1].set_title('Loss (MSE) do modelo por época', fontsize=18)\n",
    "ax[1].set_ylabel('Loss (MSE)', fontsize=14)\n",
    "ax[1].set_xlabel('Época', fontsize=14)\n",
    "ax[1].legend(['Treino', 'Validação'], loc='upper left', fontsize=16)\n",
    "\n",
    "# Ajuste do layout do plot\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
